import streamlit as st
import pandas as pd
import FinanceDataReader as fdr
import numpy as np
from datetime import datetime, timedelta
import time
import concurrent.futures
import updater_utils
from crawl_holdings import fetch_etf_holdings
from utils_config import load_etf_holdings, ETF_UNIVERSE
from db_manager import save_etf_universe, save_etf_holdings, get_etf_holdings
from streamlit.runtime.scriptrunner import get_script_run_ctx, add_script_run_ctx

# -----------------------------------------------------------------------------
# Data Caching & Management
# -----------------------------------------------------------------------------

@st.cache_data(ttl=3600*12)
def get_stock_data_cached(ticker, start_date, end_date):
    """ê°œë³„ ì¢…ëª© ë°ì´í„°ë¥¼ ìµœì í™”í•˜ì—¬ ì¡°íšŒí•˜ê³  ì¸ë±ìŠ¤ë¥¼ í‘œì¤€í™”í•©ë‹ˆë‹¤."""
    for attempt in range(2): # 2ë²ˆ ì‹œë„
        try:
            df = fdr.DataReader(ticker, start_date, end_date)
            if not df.empty:
                # ì¸ë±ìŠ¤ í‘œì¤€í™” (Date)
                if df.index.name != 'Date':
                    df.index.name = 'Date'
                return df
            break
        except Exception:
            time.sleep(0.5)
            continue
    return pd.DataFrame()

@st.cache_data(ttl=3600*12) 
def fetch_market_data(days=2500):
    """ì „ì²´ ìœ ë‹ˆë²„ìŠ¤ì˜ ì‹œì¥ ë°ì´í„°ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜ì§‘í•˜ê³  ì‚¬ì „ ì—°ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    data_dict = {}
    end_date = datetime.now()
    start_date = datetime(2020, 1, 1)
    
    # 1. ì½”ìŠ¤ë‹¥ ì§€ìˆ˜ (ì‹œì¥ ì˜¨ë„ê³„ ê¸°ì¤€)
    try:
        kosdaq = fdr.DataReader('KQ11', start_date, end_date)
        if not kosdaq.empty:
            kosdaq.index.name = 'Date'
            data_dict['KOSDAQ'] = kosdaq
    except: pass

    total = len(ETF_UNIVERSE)
    if total == 0: return data_dict

    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # 2. ë³‘ë ¬ ìˆ˜ì§‘ ë° ì‚¬ì „ ê³„ì‚° í•¨ìˆ˜
    def fetch_one(ticker):
        from analysis_engine import add_momentum_columns # ìˆœí™˜ ì°¸ì¡° ë°©ì§€
        
        for attempt in range(2): # ê°„ì´ ë¦¬íŠ¸ë¼ì´
            try:
                df = fdr.DataReader(ticker, start_date, end_date)
                # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ KOSPI ì ‘ë¯¸ì‚¬ ì‹œë„
                if df.empty or len(df) < 10:
                    try: df = fdr.DataReader(f"{ticker}.KS", start_date, end_date)
                    except: pass
                
                if not df.empty and len(df) > 10:
                    df.index.name = 'Date'
                    # ìœ íš¨ ì»¬ëŸ¼ë§Œ í†µí•©
                    cols = ['Open', 'High', 'Low', 'Close', 'Volume']
                    df = df[[c for c in cols if c in df.columns]].copy()
                    
                    # [Pre-calculation] ëª¨ë©˜í…€ ì ìˆ˜ ë° ë³´ì¡°ì§€í‘œ ì„ í–‰ ê³„ì‚°
                    df = add_momentum_columns(df)
                    df['Name'] = ETF_UNIVERSE.get(ticker, {}).get('name', 'Unknown')
                    return ticker, df
                break
            except:
                time.sleep(0.2)
        return ticker, None

    # 3. ThreadPoolExecutor (ìµœì í™”ëœ ë³‘ë ¬ ì‹¤í–‰)
    sorted_tickers = sorted(ETF_UNIVERSE.keys())
    completed = 0
    ctx = get_script_run_ctx()
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=15) as executor:
        if ctx:
            futures = {executor.submit(lambda t=t: (add_script_run_ctx(ctx), fetch_one(t))[1]): t for t in sorted_tickers}
        else:
            futures = {executor.submit(fetch_one, t): t for t in sorted_tickers}
        
        for future in concurrent.futures.as_completed(futures):
            completed += 1
            try:
                t, df = future.result()
                if df is not None:
                    data_dict[t] = df
            except: pass
            
            if completed % 5 == 0 or completed == total:
                progress_bar.progress(completed / total)
                status_text.text(f"ì‹œì¥ ë°ì´í„° ë¡œë”© ì¤‘... [{completed}/{total}]")

    status_text.empty()
    progress_bar.empty()
    return data_dict

def run_data_update():
    """ì „ì²´ ë°ì´í„° ìµœì‹ í™” (ëª©ë¡ ê°±ì‹  -> ë³´ìœ ì¢…ëª© DB ì—…ë°ì´íŠ¸)"""
    status_cont = st.empty()
    prog_bar = st.progress(0)
    
    # 1. ETF ëª©ë¡ ê°±ì‹ 
    status_cont.info("ğŸ“‹ ETF ì „ì²´ ëª©ë¡ ê°±ì‹  ì¤‘... (Seibro/Naver)")
    new_universe_list = updater_utils.update_etf_list_seibro_param() 
    
    # DBì— ìœ ë‹ˆë²„ìŠ¤ ì •ë³´ ì €ì¥
    save_etf_universe(new_universe_list)
    
    # 2. ë³´ìœ ì¢…ëª© ì—…ë°ì´íŠ¸ (ìŠ¤ë§ˆíŠ¸ ì—…ë°ì´íŠ¸)
    status_cont.info("ğŸ“¦ ETF ë³´ìœ  ì¢…ëª© ì •ë³´ DB ì—…ë°ì´íŠ¸ ì¤‘...")
    
    today_str = datetime.now().strftime('%Y-%m-%d')
    total = len(new_universe_list)
    updated_count = 0
    skipped_count = 0
    
    for i, etf in enumerate(new_universe_list):
        prog_bar.progress((i+1)/total)
        ticker = etf['ticker']
        name = etf['name']
        
        # ì„±ë¶„ ë¡œë“œ (DBì—ì„œ í™•ì¸)
        existing_holdings = get_etf_holdings(ticker)
        if existing_holdings:
            # db_managerëŠ” updated_atì„ í…Œì´ë¸”ì— ì €ì¥í•˜ë¯€ë¡œ, 
            # ê°œë³„ ì¡°íšŒê°€ ê°€ëŠ¥í•˜ë‚˜ ì—¬ê¸°ì„œëŠ” íš¨ìœ¨ì„ ìœ„í•´ ë¡œì§ ë‹¨ìˆœí™”
            # (ì˜¤ëŠ˜ ì´ë¯¸ ì—…ë°ì´íŠ¸í–ˆë‹¤ë©´ ìŠ¤í‚µ)
            pass 

        status_cont.text(f"[{i+1}/{total}] {name} ì—…ë°ì´íŠ¸ ì¤‘...")
        holdings = fetch_etf_holdings(ticker)
        
        if holdings:
            save_etf_holdings(ticker, holdings)
            updated_count += 1
        else:
            skipped_count += 1
            
        time.sleep(0.1)
        
    status_cont.success(f"âœ… DB ì—…ë°ì´íŠ¸ ì™„ë£Œ! (ê°±ì‹ : {updated_count}, ì‹¤íŒ¨/ê¸°ì¡´: {skipped_count})")
    st.cache_data.clear()
    time.sleep(2)
    st.rerun()
